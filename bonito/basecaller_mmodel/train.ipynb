{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/princezwang/.conda/envs/bonito_env/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layers.0.weight torch.Size([6, 48, 1])\n",
      "layers.0.bias torch.Size([6])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--size neurons] [--stride samples]\n",
      "                             [--winlen WINLEN] [--adam beta1 beta2]\n",
      "                             [--eps adjustment] [--niteration batches]\n",
      "                             [--weight_decay penalty]\n",
      "                             [--gradient_clip_num_mads num_MADs]\n",
      "                             [--lr_max rate] [--lr_min rate] [--seed integer]\n",
      "                             [--sharpen min max niter]\n",
      "                             [--warmup_batches WARMUP_BATCHES]\n",
      "                             [--lr_warmup rate] [--min_momentum MIN_MOMENTUM]\n",
      "                             [--filter_max_dwell multiple]\n",
      "                             [--filter_mean_dwell radius]\n",
      "                             [--filter_min_pass_fraction fraction]\n",
      "                             [--filter_path_buffer ratio] [--limit LIMIT]\n",
      "                             [--reverse] [--sample_nreads_before_filtering n]\n",
      "                             [--chunk_len_min samples]\n",
      "                             [--chunk_len_max samples]\n",
      "                             [--include_reporting_strands]\n",
      "                             [--input_strand_list INPUT_STRAND_LIST]\n",
      "                             [--min_sub_batch_size chunks]\n",
      "                             [--reporting_percent_reads sub_batches]\n",
      "                             [--reporting_strand_list REPORTING_STRAND_LIST]\n",
      "                             [--reporting_sub_batches sub_batches]\n",
      "                             [--standardize] [--sub_batches sub_batches]\n",
      "                             [--device DEVICE] [--full_filter_status]\n",
      "                             [--outdir OUTDIR] [--overwrite] [--quiet]\n",
      "                             [--save_every x] [--mod_factor start final niter]\n",
      "                             [--mod_prior_factor MOD_PRIOR_FACTOR]\n",
      "                             [--num_mod_weight_reads NUM_MOD_WEIGHT_READS]\n",
      "                             [--version]\n",
      "                             model input\n",
      "ipykernel_launcher.py: error: ambiguous option: --f=/home/princezwang/.local/share/jupyter/runtime/kernel-v2-596789Yv2vcQe4IPg5.json could match --filter_max_dwell, --filter_mean_dwell, --filter_min_pass_fraction, --filter_path_buffer, --full_filter_status\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/princezwang/.conda/envs/bonito_env/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3406: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Bonito Model template\n",
    "\"\"\"\n",
    "\n",
    "from pickletools import optimize\n",
    "import numpy as np\n",
    "\n",
    "from torch import  nn, optim\n",
    "from bonito.nn import Permute, layers\n",
    "import torch\n",
    "from torch.nn.functional import log_softmax, ctc_loss\n",
    "from torch.nn import Module, ModuleList, Sequential, Conv1d, BatchNorm1d, Dropout\n",
    "import toml\n",
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from bonito.util import __models__, default_config, default_data, load_model\n",
    "from bonito.util import  load_symbol, init, half_supported, permute\n",
    "from bonito.training import load_state, Trainer\n",
    "from fast_ctc_decode import beam_search, viterbi_search\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from bonito.reader import Reader\n",
    "\n",
    "from train_flipflop import gen_batch\n",
    "from _bin_argparse import get_train_flipflop_parser\n",
    "class Decoder(Module):\n",
    "    \"\"\"\n",
    "    Decoder\n",
    "    \"\"\"\n",
    "    def __init__(self, features, classes):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.layers = Sequential(\n",
    "            Conv1d(features, classes, kernel_size=1, bias=True),\n",
    "            Permute([2, 0, 1])\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return log_softmax(self.layers(x), dim=-1)\n",
    "\n",
    "def decode_ref(encoded, labels):\n",
    "    \"\"\"\n",
    "    Convert a integer encoded reference into a string and remove blanks\n",
    "    \"\"\"\n",
    "    return ''.join(labels[e] for e in encoded.tolist() if e)\n",
    "\n",
    "dirname = \"/home/princezwang/software/bonito/bonito/models/dna_r9.4.1@v2\"\n",
    "if not os.path.isdir(dirname) and os.path.isdir(os.path.join(__models__, dirname)):\n",
    "    dirname = os.path.join(__models__, dirname)\n",
    "pretrain_file = os.path.join(dirname, 'config.toml')\n",
    "config = toml.load(pretrain_file)\n",
    "if 'lr_scheduler' in config:\n",
    "    print(f\"[ignoring 'lr_scheduler' in --pretrained config]\")\n",
    "    del config['lr_scheduler']\n",
    "model = load_model(dirname, 'cpu')\n",
    "\n",
    "\n",
    "\n",
    "# model = load_symbol(config, 'Model')(config)\n",
    "# scores = model(torch.randn(260,1,1000))\n",
    "# seqs = [model.decode(x) for x in permute(scores, 'TNC', 'NTC')]\n",
    "decoder_ww = model.state_dict()[\"decoder.layers.0.weight\"]\n",
    "decoder_bias = model.state_dict()[\"decoder.layers.0.bias\"]\n",
    "decoder_ww = torch.cat([decoder_ww,decoder_ww[2].reshape(-1,48,1)])\n",
    "decoder_bias = torch.cat([decoder_bias,decoder_bias[2].reshape(-1)],0)\n",
    "decoder_m = Decoder(48,6)\n",
    "param_new = {}\n",
    "for key in decoder_m.state_dict().keys():\n",
    "    param_new[key] = decoder_m.state_dict()[key]\n",
    "    print(key, decoder_m.state_dict()[key].shape)\n",
    "param_new['layers.0.weight'] = decoder_ww\n",
    "param_new['layers.0.bias'] = decoder_bias\n",
    "decoder_m.load_state_dict(param_new)\n",
    "model.decoder = decoder_m\n",
    "model.alphabet = ['N', 'A', 'C', 'G', 'T', 'M']\n",
    "\n",
    "# for p in model.encoder.parameters():\n",
    "#     p.requires_grad=False\n",
    "\n",
    "optimizer = optim.Adam(filter(lambda p:p.requires_grad, model.parameters()), lr=1e-4)\n",
    "main_batch = gen_batch(get_train_flipflop_parser().parse_args())\n",
    "batch_list = list(main_batch)\n",
    "batch_tensor, seqref, seqlen = batch_list[0][0],batch_list[0][1],batch_list[0][2]\n",
    "losses = []\n",
    "\n",
    "for i in range(100):\n",
    "    optimizer.zero_grad()\n",
    "    tmp = permute(batch_tensor,[0,1,2],[1,2,0]) \n",
    "    scores = model(tmp)\n",
    "    # seqs = [model.decode(x) for x in permute(scores, 'TNC', 'NTC')]\n",
    "    loss = model.ctc_label_smoothing_loss(scores, seqref, seqlen)\n",
    "    loss['total_loss'].backward()\n",
    "    nn.utils.clip_grad_norm_(model.decoder.parameters(), max_norm=2, norm_type=2)\n",
    "    optimizer.step()\n",
    "    losses.append(loss['total_loss'])\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('bonito_env': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "edc9de87d5f7cbbbc5e8998f9d68b8ac511285245709bc72d1b3b2821f60c486"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
